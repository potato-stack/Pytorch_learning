{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE BOOK FOR PYTORCH TENSOR TYPE AND DEFINITION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "### Common type and syntax of creating tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Tensor support for multiple type go from a scalar -> vector -> matrix -> actual tensor it self\n",
    "scalar = torch.tensor([[[1,2,3],\n",
    "\t\t\t\t\t\t[3,4,5],\n",
    "\t\t\t\t\t\t[5,6,7]]])\n",
    "print(scalar.ndim)\n",
    "print(scalar.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 244, 244]) 3\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# create random tensor since neural network learn from this shiet\n",
    "random_ten = torch.rand(3, 244, 244)\n",
    "print(random_ten.shape, random_ten.ndim)\n",
    "\n",
    "ones = torch.ones(3,4)\n",
    "print(ones.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1, 31, 61, 91], device='cuda:0')\n",
      "tensor([0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#use torch.arange() instead of torch.range()\n",
    "print(torch.arange(start=1, end=100, step=30).cuda())\n",
    "\n",
    "# creating tensors like \n",
    "ten_zeroes = torch.zeros_like(input = torch.arange(start=1, end=100, step=30))\n",
    "print(ten_zeroes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.]], dtype=torch.float16)\n",
      "tensor([[2., 1., 0.]], device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#Now for tensor datatype \n",
    "# Big 3 issues that you will frequently have when using this bad boyis \n",
    "# - Out of shape (mine persional normally encouter)\n",
    "# - Not correct device \n",
    "# - Not right datatype\n",
    "temp = torch.ones(size=(1,3),  dtype=torch.float32)\n",
    "print(temp.type(torch.float16))\n",
    "print(torch.tensor([3.0, 2.0, 1.0], dtype=torch.float64, device=\"cuda\", requires_grad=False) - temp.cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.0000, 2.1000, 1.1000])\n",
      "tensor([-2.0000, -0.1000,  1.9000])\n"
     ]
    }
   ],
   "source": [
    "float_16_tensor = torch.tensor([3.0, 2.1, 1.1], dtype=torch.float32)\n",
    "print(float_16_tensor)\n",
    "int_32_tensor = torch.tensor([1,2,3], dtype=torch.int32)\n",
    "print(int_32_tensor - float_16_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting information from tensor \n",
    "\n",
    "### 1. Tensors not right datatype - to do get datatype from a tensor, can use 'tensor.dtype'\n",
    "### 2. Tensor not right shape - to get shape from a tensor, can use tensor.shape\n",
    "### 3. Tensors not on the right device - to get device from a tensor, use tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand(size = (3,4), device= 0)\n",
    "some_tensor\n",
    "# print the datatype of tensor \n",
    "some_tensor.dtype\n",
    "# print the shape of the tensor \n",
    "some_tensor.shape\n",
    "# print device of the tensor\n",
    "some_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating Tensors common method \n",
    "\n",
    "Some common operations are: \n",
    " - `\"+\"` Addition \n",
    " - `\"-\"` Subtraction\n",
    " - `\"*\"` Multiplication (element-wise)\n",
    " - `\"/\"` Devision\n",
    " - `\"@\"` Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11, 12, 13])\n",
      "tensor([10, 20, 30])\n",
      "tensor([-9, -8, -7])\n",
      "tensor([10, 20, 30])\n",
      "tensor([11, 12, 13])\n"
     ]
    }
   ],
   "source": [
    "# Maniplulate tensors:\n",
    "tensor = torch.tensor([1,2,3])\n",
    "print(tensor + 10)\n",
    "print(tensor * 10)\n",
    "print(tensor - 10)\n",
    "\n",
    "# You can even try Pytorch built in function\n",
    "# Note thta mul here is matrix mul not element wise \n",
    "print(torch.mul(tensor, 10))\n",
    "print(torch.add(tensor, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix mul\n",
    "\n",
    "Two main ways of doing this mul: \n",
    "1. Element wise\n",
    "2. Dot product\n",
    "\n",
    "There are two main rules that performing dot product - matrix multiplication must satisfy: \n",
    "1. The **inner dimension** must match: \n",
    "* The columns of the left hand side must equal rows on the right hand side. \n",
    "* `(3, 2) @ (2, 3)` -> will work \n",
    "2. The resulting matrix will have the shape of **outer dimension**\n",
    "* The resulting matrix will have the rows of the left hand side and columns of the right hand side.\n",
    "* `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
    "\n",
    "To make the matrix multiplcation satisfy the rule, one common method is **transpose**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 3, 5],\n",
      "        [3, 5, 7]])\n",
      "tensor([[3, 3, 5],\n",
      "        [3, 5, 7]])\n",
      "torch.Size([3, 3])\n",
      "tensor([[18, 24, 36],\n",
      "        [24, 34, 50],\n",
      "        [36, 50, 74]])\n",
      "Mulitiply two matrix with shape torch.Size([3, 2]) for torch.Size([2, 3]) will give use torch.Size([3, 3])\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#  The transpose method\n",
    "tensor = torch.tensor([[3,3],\n",
    "\t\t\t\t\t   [3,5],\n",
    "\t\t\t\t\t   [5,7]])\n",
    "tensorB = torch.tensor([[3,3],\n",
    "\t\t\t\t\t   [3,5],\n",
    "\t\t\t\t\t   [5,7]])\n",
    "\n",
    "# You can use alternate between the attribute T and torch built in method\n",
    "print(torch.transpose(tensorB, 0, -1))\n",
    "print(tensorB.T)\n",
    "\n",
    "print(torch.matmul(tensor, torch.transpose(tensorB, 0, -1)).shape)\n",
    "print(torch.matmul(tensor, tensorB.T))\n",
    "\n",
    "# You can also see that the resulting matrix shape is \n",
    "print(f\"Mulitiply two matrix with shape {tensor.shape} for {tensorB.T.shape} will give use {torch.matmul(tensor, tensorB.T).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some more common synxtax use as in nummpy: min, max, sum ... (aggregation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n",
      "tensor(90.)\n",
      "tensor(45.)\n",
      "tensor(450.)\n",
      "tensor(0.)\n",
      "tensor(90.)\n",
      "tensor(45.)\n",
      "tensor(450.)\n",
      "tensor(0)\n",
      "tensor(9)\n",
      "torch.return_types.sort(\n",
      "values=tensor([ 0., 10., 20., 30., 40., 50., 60., 70., 80., 90.]),\n",
      "indices=tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]))\n"
     ]
    }
   ],
   "source": [
    "# x = torch.arange(0, 100, 10)\n",
    "x = torch.arange(start=0, end=100, step=10, dtype = torch.float32)\n",
    "\n",
    "# You can once again use the built in Pytorch method\n",
    "print(torch.min(x))\n",
    "print(torch.max(x))\n",
    "print(torch.mean(x.type(torch.float32)))\n",
    "print(torch.sum(x))\n",
    "\n",
    "# Or you can use the attribute way \n",
    "print(x.min())\n",
    "print(x.max())\n",
    "print(x.mean())\n",
    "print(x.sum())\n",
    "\n",
    "# you can print out the index where minimum value occur\n",
    "print(torch.argmin(x))\n",
    "print(torch.argmax(x))\n",
    "print(torch.sort(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "\n",
    "* Reshaping - reshapre an input tensor into a defined shape \n",
    "* View - return a view of an input tensor of certain shape but keep the same memories as the original tensor\n",
    "* Stacking - combine multiple tensors on top / side by side of each other\n",
    "* Squeeze - remove all '1' dimensions\n",
    "* Unsqueeze - add a '1' dimensions\n",
    "* Permute - return a view of the input with dimension permuted (swapped) in certain way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.]) torch.Size([12])\n"
     ]
    }
   ],
   "source": [
    "# Let's create a tensor \n",
    "import torch\n",
    "x = torch.arange(start = 1.0, end = 13.0, dtype=torch.float32)\n",
    "print(x, x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "# Add an extra dimentsion \n",
    "x_reshaped = x.reshape(4, 3)\n",
    "print(x_reshaped)\n",
    "print(x_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.],\n",
      "        [ 5., 10., 11., 12.]])\n",
      "tensor([ 5.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  5., 10., 11., 12.])\n"
     ]
    }
   ],
   "source": [
    "# Change the view\n",
    "z = x.view(3, 4)\n",
    "print(z)\n",
    "\n",
    "# view = reshape but NOT create a copy, mean that view share the same mem as the original \n",
    "# Lets change all the row first number in to 5\n",
    "z[:, 0] = 5\n",
    "\n",
    "# You can see that changing z -> change x\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4612, 0.2184, 0.8372, 0.8899],\n",
      "        [0.2824, 0.5803, 0.0998, 0.9408],\n",
      "        [0.7586, 0.2325, 0.4643, 0.3805]])\n",
      "tensor([[[0.4612, 0.2184, 0.8372, 0.8899],\n",
      "         [0.4612, 0.2184, 0.8372, 0.8899],\n",
      "         [0.4612, 0.2184, 0.8372, 0.8899],\n",
      "         [0.4612, 0.2184, 0.8372, 0.8899]],\n",
      "\n",
      "        [[0.2824, 0.5803, 0.0998, 0.9408],\n",
      "         [0.2824, 0.5803, 0.0998, 0.9408],\n",
      "         [0.2824, 0.5803, 0.0998, 0.9408],\n",
      "         [0.2824, 0.5803, 0.0998, 0.9408]],\n",
      "\n",
      "        [[0.7586, 0.2325, 0.4643, 0.3805],\n",
      "         [0.7586, 0.2325, 0.4643, 0.3805],\n",
      "         [0.7586, 0.2325, 0.4643, 0.3805],\n",
      "         [0.7586, 0.2325, 0.4643, 0.3805]]])\n"
     ]
    }
   ],
   "source": [
    "# Stack tensors on top of each other\n",
    "temp = torch.rand(3,4)\n",
    "print(temp)\n",
    "x_stacked = torch.stack([temp, temp, temp, temp], dim = 1)\n",
    "print(x_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1515, 0.8446, 0.8516],\n",
      "        [0.3870, 0.1983, 0.2425]])\n",
      "tensor([[[0.1515],\n",
      "         [0.8446],\n",
      "         [0.8516]],\n",
      "\n",
      "        [[0.3870],\n",
      "         [0.1983],\n",
      "         [0.2425]]])\n",
      "tensor([[[0.1515],\n",
      "         [0.8446],\n",
      "         [0.8516]],\n",
      "\n",
      "        [[0.3870],\n",
      "         [0.1983],\n",
      "         [0.2425]]])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.rand(1,2,1,3,1)\n",
    "print(temp.squeeze())\n",
    "squeeze_tensor = temp.squeeze()\n",
    "print(squeeze_tensor.unsqueeze(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9731, 0.7827, 0.1330, 0.7750, 0.0914],\n",
      "         [0.3605, 0.6484, 0.3072, 0.7695, 0.6082],\n",
      "         [0.2803, 0.5010, 0.1451, 0.7355, 0.0177],\n",
      "         [0.8040, 0.3425, 0.2002, 0.3939, 0.9618]],\n",
      "\n",
      "        [[0.7434, 0.4583, 0.2253, 0.4913, 0.1653],\n",
      "         [0.1502, 0.1087, 0.6227, 0.1958, 0.1295],\n",
      "         [0.2144, 0.6279, 0.7180, 0.2006, 0.4090],\n",
      "         [0.7050, 0.9341, 0.4218, 0.9217, 0.3667]],\n",
      "\n",
      "        [[0.7070, 0.1681, 0.7539, 0.8611, 0.6437],\n",
      "         [0.2146, 0.0724, 0.0945, 0.3786, 0.7614],\n",
      "         [0.1135, 0.1338, 0.7858, 0.0520, 0.3367],\n",
      "         [0.6078, 0.0083, 0.6693, 0.1390, 0.4636]]])\n",
      "tensor([[[0.9731, 0.3605, 0.2803, 0.8040],\n",
      "         [0.7434, 0.1502, 0.2144, 0.7050],\n",
      "         [0.7070, 0.2146, 0.1135, 0.6078]],\n",
      "\n",
      "        [[0.7827, 0.6484, 0.5010, 0.3425],\n",
      "         [0.4583, 0.1087, 0.6279, 0.9341],\n",
      "         [0.1681, 0.0724, 0.1338, 0.0083]],\n",
      "\n",
      "        [[0.1330, 0.3072, 0.1451, 0.2002],\n",
      "         [0.2253, 0.6227, 0.7180, 0.4218],\n",
      "         [0.7539, 0.0945, 0.7858, 0.6693]],\n",
      "\n",
      "        [[0.7750, 0.7695, 0.7355, 0.3939],\n",
      "         [0.4913, 0.1958, 0.2006, 0.9217],\n",
      "         [0.8611, 0.3786, 0.0520, 0.1390]],\n",
      "\n",
      "        [[0.0914, 0.6082, 0.0177, 0.9618],\n",
      "         [0.1653, 0.1295, 0.4090, 0.3667],\n",
      "         [0.6437, 0.7614, 0.3367, 0.4636]]])\n",
      "tensor([[[0.9731, 0.7434, 0.7070],\n",
      "         [0.3605, 0.1502, 0.2146],\n",
      "         [0.2803, 0.2144, 0.1135],\n",
      "         [0.8040, 0.7050, 0.6078]],\n",
      "\n",
      "        [[0.7827, 0.4583, 0.1681],\n",
      "         [0.6484, 0.1087, 0.0724],\n",
      "         [0.5010, 0.6279, 0.1338],\n",
      "         [0.3425, 0.9341, 0.0083]],\n",
      "\n",
      "        [[0.1330, 0.2253, 0.7539],\n",
      "         [0.3072, 0.6227, 0.0945],\n",
      "         [0.1451, 0.7180, 0.7858],\n",
      "         [0.2002, 0.4218, 0.6693]],\n",
      "\n",
      "        [[0.7750, 0.4913, 0.8611],\n",
      "         [0.7695, 0.1958, 0.3786],\n",
      "         [0.7355, 0.2006, 0.0520],\n",
      "         [0.3939, 0.9217, 0.1390]],\n",
      "\n",
      "        [[0.0914, 0.1653, 0.6437],\n",
      "         [0.6082, 0.1295, 0.7614],\n",
      "         [0.0177, 0.4090, 0.3367],\n",
      "         [0.9618, 0.3667, 0.4636]]])\n"
     ]
    }
   ],
   "source": [
    "# permute - rearange the tensor element in a specify oder - also can under stand that you suffle up existing dimensions\n",
    "temp = torch.rand(3,4,5)\n",
    "print(temp)\n",
    "print(torch.permute(temp, (2,0,1)))\n",
    "print(torch.permute(temp, (2,1,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing (selecting element from a tensor)\n",
    "Indexing in Pytorch share a large portion of simliarity to Numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor([1, 2, 3])\n",
      "tensor(5)\n",
      "tensor([[1, 2, 3]])\n",
      "tensor([[2, 5, 8]])\n",
      "tensor([1, 2, 3])\n",
      "tensor(9)\n",
      "tensor([[7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(start= 1, end= 10, step=1).reshape(1, 3 , 3)\n",
    "print(x)\n",
    "print(x[0])\n",
    "print(x[0][0])\n",
    "print(x[0][1][1])\n",
    "\n",
    "\n",
    "print(x[:, 0])\n",
    "print(x[:, :, 1])\n",
    "print(x[0, 0, :])\n",
    "\n",
    "print(x[-1][-1][-1])\n",
    "print(x[:, :, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch and Numpy\n",
    "NumPy goes very well with PyTorch, PyTorch installation need NumPy, and interact very well with it. \n",
    "* Data in NumPy, have to convert into torch type to interact: `torch.from_numpy(ndarray)`\n",
    "* Convert from PyTorch -> NumPy -> `torch.tensor.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4]\n",
      "tensor([2, 3, 4, 5], dtype=torch.int32)\n",
      "[[[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1.]]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "another_array = np.array([1,2,3,4])\n",
    "print(another_array)\n",
    "tensor = torch.from_numpy(another_array + 1)\n",
    "\n",
    "# Default data for numpy is float64 so torch reflect that data type\n",
    "print(tensor)\n",
    "\n",
    "tensor = torch.ones(3,4,4)\n",
    "numpy_tensor = tensor.numpy()\n",
    "# Default data of pytorch is 64, convert it to numpy will make numpy reflect that\n",
    "print(numpy_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility (trying to make random out of random)\n",
    "\n",
    "In short a neural network will learn like this: \n",
    "* Throw in a bunch random set of weight -> run the input through the network -> compare it with ground truth -> figure out how \"wrong\" is the output -> figure out how much to ajust the weight (back propagation) -> again .... \n",
    "* those run input through network, and ajust the weight bascially tensor operation\n",
    "\n",
    "To reduce the randomnes in neural networks, PyTorch use random seed, to yeild the random. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829],\n",
      "        [0.9593, 0.3904, 0.6009],\n",
      "        [0.2566, 0.7936, 0.9408]])\n",
      "tensor([[0.8823, 0.9150, 0.3829],\n",
      "        [0.9593, 0.3904, 0.6009],\n",
      "        [0.2566, 0.7936, 0.9408]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Random in computer is not actually random, it is psuedo random, and if random start with a seed each time it will give us the same results\n",
    "# each manual seed only work with one block of the next rand code\n",
    "torch.manual_seed(42)\n",
    "random_tensor_A = torch.rand(size=(3,3))\n",
    "torch.manual_seed(42)\n",
    "random_tensor_B = torch.rand(size=(3,3))\n",
    "print(random_tensor_A)\n",
    "print(random_tensor_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running pytorch's tensor computing on GPU\n",
    "\n",
    "GPUs = parrallel - this is extremlly powerfull since tensor operation basically matrix multiplying "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting a GPU\n",
    "1. Easiest - Use Google colab\n",
    "2. Use your own GPU - instal CUDA, Cudnn, add it to path (Window)/source(Linux) and install the Torch with GPU version. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jan 25 19:13:51 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 561.09                 Driver Version: 561.09         CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3060 Ti   WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| 33%   43C    P8             31W /  200W |    1416MiB /   8192MiB |     24%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      7372    C+G   ...a\\Local\\Programs\\Opera GX\\opera.exe      N/A      |\n",
      "|    0   N/A  N/A      7852      C   ...rograms\\Python\\Python311\\python.exe      N/A      |\n",
      "|    0   N/A  N/A      9128    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A      9296    C+G   ...a\\Local\\Programs\\Opera GX\\opera.exe      N/A      |\n",
      "|    0   N/A  N/A     15204    C+G   ...B\\system_tray\\lghub_system_tray.exe      N/A      |\n",
      "|    0   N/A  N/A     16168    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     19184    C+G   ...1.0_x64__8wekyb3d8bbwe\\Video.UI.exe      N/A      |\n",
      "|    0   N/A  N/A     20712    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     20816    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A     24600    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     25124    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     26264    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe      N/A      |\n",
      "|    0   N/A  N/A     26804    C+G   ....0_x64__kzh8wxbdkxb8p\\DCv2\\DCv2.exe      N/A      |\n",
      "|    0   N/A  N/A     27616    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Check for GPU accessable with pytorch \n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# count the number of GPUs\n",
    "print(torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Putting tensors (and model) on the GPU\n",
    "The reason why we'd like to do this because the GPU is way more faster than CPU in computing tensor operations - the parallel ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor (default on CPU)\n",
    "tensor = torch.tensor([1,2,3])\n",
    "print(tensor.device)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "print(tensor_on_gpu.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "### 3. Putting the tensor back to the CPU \n",
    "\n",
    "numpy_tensor = tensor_on_gpu.to(\"cpu\").numpy()\n",
    "print(numpy_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
